---
title: "Analysis of Stack Overflow Q&A"
author: "Semih Barutcu"
date: "12/11/2020"
output: pdf_document
---

I used a kaggle dataset about the topic StackSample: 10% of Stack Overflow Q&A. The link for the dataset: https://www.kaggle.com/stackoverflow/stacksample

This dataset includes questions, answers and tags as text of 10% of questions and answers from the Stack Overflow. I would like to do data exploration over these datasets and study tf-idf. I would like to work on an appropriate machine learning algorithm for these dataset lastly. 

I have done an introductory data explorations until now using Text Mining with R: A Tidy Approach by Julia Silge and David Robinson book as a reference. 

## Preprocessing

```{r warning=F, message=F}
library(pacman)

p_load(dplyr, tidytext, ggplot2, wordcloud, stringr, lubridate)
```

```{r}
questions <- read.csv("data/Questions.csv")

tags <- read.csv("data/Tags.csv")

answers <- read.csv("data/Answers.csv")
```

Date are formatted by lubridate package function ymd_hms().

```{r}
questions$CreationDate <- ymd_hms(questions$CreationDate)
questions$ClosedDate <- ymd_hms(questions$ClosedDate)
```


I used the first 100,000 observations to work at the beginning. I used smaller datasets where my 16 GB RAM is not sufficient for size of datasets.

```{r}
set.seed(123)
tag_small <- sample_n(tags, 100000)

q_small <- sample_n(questions, 30000)
```


## Exploratory Data Analysis (EDA)

### Tags 

Tags are formed by unnesting tokens. 

```{r}
tags <- tags %>% 
  unnest_tokens(tag, Tag)

tag_small <- tag_small %>% 
  unnest_tokens(tag, Tag)
```


You can see counts of 15 most common the tags dataset below.

```{r, message=F}
tags %>%  
  group_by(tag) %>% 
  summarize(n = n()) %>% 
  top_n(15) %>% 
  ggplot(aes(tag, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

### Questions

Body of questions are formed as singular words by unnesting tokens after some signs and stop words are removed. Stop words are some of most common words such as “the,” “of,” “to,” and so forth in English which are not identifying and not useful for an analysis.  

```{r}
# I used same stop words and a similar querying on q_word with work of Julia Silge
# The notebook can be found here: https://www.kaggle.com/juliasilge/tf-idf-of-stack-overflow-questions
# eliminate the words gt and lt which are used for greater than and less than.
my_stop_words <- bind_rows(stop_words %>%
                             filter(lexicon == "snowball"), 
                           tibble(word = c("gt", "lt"), 
                                      lexicon = rep("custom", 2)))

q_small <- q_small %>% 
  mutate(Body = str_replace_all(Body, "<[^>]*>", "")) %>%
  unnest_tokens(word, Body) %>% 
  filter(str_detect(word, "^[a-z]")) %>%
  filter(str_detect(word, "[0-9]", negate = T)) %>%
  filter(!word %in% c("cccccccccccccccc", "welcome.seamlessoffers.com", "interfashionadmin.theindiestudio.com.interfashionadmin", "www.flashmo.com", "uh", "xe:djxdatagridcolumn", "iloå", "fcalias", "bigdecimal.new", "www.questdesign.com.au", "linkedbinarytree", "tempchunktype", "date_seconds", "stylist_employment_type")) %>%
  anti_join(my_stop_words, by = "word") 
```


You can see the most common words on the Body part of small questions dataset. code, class and file are top 3 words. Most of the words are not useful to identify the tags because they are not belong to a specific language while some of them can help us eliminating some tags. For example, class word is used for an Object-oriented programming (OOP) language most probably or amp is an open-source custom web development framework created to speed up the loading time of web pages on mobile devices and the word is related with this framework. 

```{r, message=F}
q_small %>%  
  group_by(word) %>% 
  anti_join(stop_words, by = "word") %>% 
  summarize(n = n(), .groups = 'drop') %>%
  top_n(20) %>% 
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

I joined the questions and tags datasets and filtered the search for some popular languages. Then, I plotted a bar graph count of each year's observations with respect to these languages. We can see the rise of total tags used by users until 2012. Java and javascript were used each year more than previous year thru 2015 while python is the only language that the total counts were increased every year. Still, c and c++ has most tags but trends show that python and javascript are the most promising languages.

```{r}
questions %>% select(Id, CreationDate) %>%
  left_join(tags, by = "Id") %>%
  filter(tag %in% c( "ruby", "python", "php", "javascript", "java", "c")) %>%
  ggplot(aes(year(CreationDate))) +
  geom_bar() +
  facet_wrap(~tag) +
  scale_x_continuous(breaks = 2007:2016, ) + 
  theme(axis.text.x = element_text(angle = 45))

```

We can see that ruby language topics have least closed dates ratio by far for the selected 6 languages. 

```{r message=F}
questions %>% select(Id, ClosedDate) %>%
  left_join(tags, by = "Id") %>%
  filter(tag %in% c( "ruby", "python", "php", "javascript", "java", "c")) %>%
  group_by(tag) %>%
  summarise(Closed_Counts = sum(!is.na(ClosedDate)), Closed_Ratio = sum(!is.na(ClosedDate))/ n() ) %>%
  arrange(desc(Closed_Ratio))
```

You can see score statistics of questions with respect to 6 computer programming languages. C has the highest average and php has the least. By looking minimum and maximum scores we can observe far away than averages, especially for maximum values. But you can see the 0.025 and 0.975 which make sense with the average. So, I can say that most of the topic are not voted much because the 95% range is narrow with an average between 1 and 2.1 while some questions are aroused interest especially in a positive way.

```{r message=F}
questions %>% select(Id, Score) %>%
  left_join(tags, by = "Id") %>%
  filter(tag %in% c( "ruby", "python", "php", "javascript", "java", "c")) %>%
  group_by(tag) %>%
  summarise(Avg = round(mean(Score), 2), Min = min(Score), Max = max(Score), Q_025 = quantile(Score, 0.025), Q_975 = quantile(Score, 0.975) ) %>%
  arrange(desc(Avg))
```

## WordCloud

```{r}
q_small %>% 
  count(word) %>%
  with(wordcloud(word, n, max.words = 30))
```


```{r}
tag_small %>% 
  count(tag) %>%
  with(wordcloud(tag, n, max.words = 25))
```


## Sentiment Analysis

I used afinn sentiments to make sentimental analysis on the questions. The AFINN lexicon assigns words with a score that runs between -5 and 5, with negative scores indicating negative sentiment and positive scores indicating positive sentiment. You can see the scores of the all questions of the small questions dataset.

```{r}
q_small %>% 
  select(Id, word) %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Id) %>%
  summarise(sentiment = sum(value), .groups = 'drop')
```

You can see the histogram of the scores below. 

```{r}
q_small %>% 
  select(Id, word) %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Id) %>%
  summarise(sentiment = sum(value), .groups = 'drop') %>%
  ggplot(aes(sentiment)) +
  geom_histogram(binwidth = 3) +
  xlim(-40, 50)

```

I calculated the count of positive and negative words and ordered them in descending order.

```{r}
q_small_afinn_count <- q_small %>%  
  select(Id, word) %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  mutate(sentiment = ifelse(value > 0, "positive", "negative")) %>%
  count(word, sentiment) %>%
  arrange(desc(n)) %>%
  top_n(24)

q_small_afinn_count
```


You can see that there are more unique negative words than positives while total number of positive words is more than negative ones. 

```{r}
q_small_afinn_count %>% 
  group_by(sentiment) %>%
  summarize(total = sum(n), count = n(), .groups = 'drop')
```

The graph shows the 10 most common negative and positive words contribution.

```{r}
q_small_afinn_count %>%
  group_by(sentiment) %>%
  top_n(10, n) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
  x = NULL) +
  coord_flip()
```


## Term Frequency

Using term frequency and inverse document frequency allows us to find words that are characteristic for one document within a collection of documents.


```{r}
q_words <- q_small %>%
  count(Id, word, sort = T) %>%
  ungroup()

total_words <- q_words %>%
  group_by(Id) %>%
  summarize(total = sum(n), .groups = 'drop')

q_words <- left_join(q_words, total_words, by = "Id")
```

The list arranged by descending tf_idf values and as you can see there are not meaningful words at all because it comes from short questions which includes related codes. As a result, it is hard to get a clear result when searching words that represent the selected tags. However, tf_idf is a strong tool to explore identifying words.

```{r}
q_words %>%
  left_join(tags, by = "Id") %>%
  filter(tag %in% c( "ruby", "python", "php", "javascript", "java", "c")) %>%
  group_by(tag) %>%
  bind_tf_idf(word, tag, n) %>% 
  arrange(desc(tf_idf)) 
```



```{r}
q_words %>%
  left_join(tags, by = "Id") %>%
  filter(tag %in% c( "ruby", "python", "php", "javascript", "java", "c")) %>%
  group_by(tag) %>% 
  bind_tf_idf(word, tag, n) %>%
  select(-Id) %>%
  arrange(desc(tf_idf)) %>%
  top_n(6) %>%
  ggplot(aes(word, tf_idf, fill = tag)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~tag, scales = "free_y")+
  coord_flip() + 
  theme(axis.text.x = element_text(angle = 30))
```

## Conclusion

As a result of this project, 

- I learned the most common tags and words in the questions between 2008-2016.
- I observed the question count of programming languages by year and the trends about it.
- I approached to questions in terms of sentiments.
- I made tf_idf analysis of the dataset even the results were not encouraging.

It's hard to work on a machine learning algorithm because of convenience of the data. Topic modeling with Latent Dirichlet Allocation (LDA) seems to be applicable on this dataset and it is a further idea to follow for me. 












